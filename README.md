# RAG-Kudo ğŸ¥‹

SystÃ¨me RAG (Retrieval-Augmented Generation) pour la formation des arbitres en Kudo. Ce projet utilise Docling pour l'ingestion de documents, LlamaIndex pour l'orchestration RAG, et OpenAI/Anthropic pour la gÃ©nÃ©ration de rÃ©ponses pÃ©dagogiques.

## ğŸ¯ Objectif

CrÃ©er un assistant intelligent pour la formation des arbitres de Kudo qui :
- RÃ©pond aux questions sur les rÃ¨gles d'arbitrage
- Cite les sources officielles du rÃ¨glement
- Fournit des exemples concrets et des explications pÃ©dagogiques
- GÃ©nÃ¨re des quiz d'entraÃ®nement
- Explique les dÃ©cisions d'arbitrage

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Documents Sources (PDF, DOCX, MD)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Docling (Extraction structurÃ©e)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Chunking (LlamaIndex)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ChromaDB (Base vectorielle)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Retriever (Recherche hybride)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM (GPT-4/Claude) + Prompts pÃ©dagogiques â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Structure du projet

```
RAG-Kudo/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # Documents sources (PDF, DOCX, etc.)
â”‚   â”œâ”€â”€ processed/        # Documents traitÃ©s par Docling
â”‚   â””â”€â”€ vectorstore/      # Base de donnÃ©es vectorielle ChromaDB
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/        # Modules d'ingestion (Docling, chunking)
â”‚   â”œâ”€â”€ retrieval/        # Vector store et retriever
â”‚   â”œâ”€â”€ generation/       # LLM et gÃ©nÃ©rateur de rÃ©ponses
â”‚   â”œâ”€â”€ evaluation/       # Ã‰valuation de la qualitÃ© RAG
â”‚   â””â”€â”€ utils/            # Utilitaires
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Configuration centralisÃ©e
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ demo.py           # Script de dÃ©monstration
â”‚   â””â”€â”€ pipeline.py       # Pipeline CLI principal
â”œâ”€â”€ notebooks/            # Jupyter notebooks pour expÃ©rimentation
â”œâ”€â”€ app/                  # Interface utilisateur (API/Streamlit)
â”œâ”€â”€ tests/                # Tests unitaires
â”œâ”€â”€ .env.example          # Template de configuration
â””â”€â”€ pyproject.toml        # Configuration uv et dÃ©pendances
```

## ğŸš€ Installation

### PrÃ©requis

- Python 3.10+
- [uv](https://github.com/astral-sh/uv) (gestionnaire de packages)
- ClÃ© API OpenAI ou Anthropic

### Installation avec uv

```bash
# Cloner le repository
git clone <repo-url>
cd RAG-Kudo

# CrÃ©er l'environnement virtuel et installer les dÃ©pendances
uv venv
source .venv/bin/activate  # Sur Windows: .venv\Scripts\activate
uv sync

# Installer les dÃ©pendances de dÃ©veloppement
uv sync --extra dev
```

### Configuration

1. Copier le fichier de configuration d'exemple :
```bash
cp .env.example .env
```

2. Ã‰diter `.env` et ajouter vos clÃ©s API :
```bash
OPENAI_API_KEY=your-openai-api-key-here
# ou
ANTHROPIC_API_KEY=your-anthropic-api-key-here
```

3. Ajuster les autres paramÃ¨tres selon vos besoins (voir `.env.example`).

## ğŸ“š Utilisation

### 1. Ajouter des documents

Placez vos documents de rÃ¨glement Kudo dans `data/raw/` :
```bash
cp /path/to/reglement_kudo.pdf data/raw/
```

Formats supportÃ©s : PDF, DOCX, Markdown, HTML

### 2. Pipeline complet

#### Option A : Script de dÃ©monstration interactif

```bash
python scripts/demo.py
```

Choisissez parmi :
1. Pipeline complet (ingestion + indexation + dÃ©mo)
2. Indexation uniquement
3. DÃ©mo retrieval et gÃ©nÃ©ration
4. GÃ©nÃ©rer un quiz

#### Option B : Pipeline CLI

```bash
# Pipeline complet en une commande
python scripts/pipeline.py full

# Ou Ã©tape par Ã©tape :

# 1. IngÃ©rer les documents
python scripts/pipeline.py ingest

# 2. CrÃ©er l'index vectoriel
python scripts/pipeline.py index

# 3. Poser une question
python scripts/pipeline.py query "Quelles sont les techniques autorisÃ©es ?"

# 4. Mode interactif
python scripts/pipeline.py interactive

# 5. Afficher les statistiques
python scripts/pipeline.py stats
```

### 3. Utilisation programmatique

```python
from src.ingestion import DoclingProcessor, SemanticChunker
from src.retrieval import VectorStoreManager, KudoRetriever
from src.generation import KudoResponseGenerator
from config import settings

# 1. Ingestion
processor = DoclingProcessor(output_dir=settings.processed_data_dir)
documents = processor.process_directory(settings.raw_data_dir)

# 2. Chunking
chunker = SemanticChunker()
nodes = chunker.chunk_multiple_documents(documents)

# 3. Indexation
manager = VectorStoreManager()
index = manager.create_index(nodes)

# 4. GÃ©nÃ©ration de rÃ©ponse
generator = KudoResponseGenerator(index=index)
result = generator.generate("Quelles sont les rÃ¨gles de scoring ?")

print(result["answer"])
print(f"Confiance: {result['confidence']}")
print(f"Sources: {result['num_sources']}")
```

## ğŸ“ FonctionnalitÃ©s

### RÃ©ponses pÃ©dagogiques

Le systÃ¨me gÃ©nÃ¨re des rÃ©ponses structurÃ©es incluant :
- La rÃ¨gle officielle exacte
- Le contexte et le raisonnement
- Des exemples concrets de situations
- Les erreurs courantes Ã  Ã©viter
- Les rÃ©fÃ©rences prÃ©cises du rÃ¨glement

### GÃ©nÃ©ration de quiz

```python
quiz = generator.generate_quiz_question(category="sanctions")
print(quiz["quiz"])
```

### Explication de dÃ©cisions

```python
result = generator.explain_decision(
    situation="Un combattant frappe aprÃ¨s l'arrÃªt de l'arbitre",
    decision="Avertissement donnÃ©"
)
print(result["explanation"])
```

### Recherche par catÃ©gorie

```python
retriever = KudoRetriever(index=index)
nodes = retriever.retrieve_by_category(
    query="sanctions possibles",
    category="sanctions"
)
```

## âš™ï¸ Configuration avancÃ©e

### ModÃ¨les LLM

Modifier dans `.env` :
```bash
# OpenAI
LLM_PROVIDER=openai
LLM_MODEL=gpt-4-turbo-preview

# Ou Anthropic
LLM_PROVIDER=anthropic
LLM_MODEL=claude-3-5-sonnet-20241022
```

### Embeddings

```bash
EMBEDDING_MODEL=text-embedding-3-small  # RecommandÃ©
# ou text-embedding-3-large pour plus de prÃ©cision
```

### Chunking sÃ©mantique

```bash
CHUNK_SIZE=800
CHUNK_OVERLAP=150
SEMANTIC_BUFFER_SIZE=1
SEMANTIC_BREAKPOINT_THRESHOLD=95
```

### Retrieval

```bash
TOP_K=5                      # Nombre de documents Ã  rÃ©cupÃ©rer
SIMILARITY_THRESHOLD=0.7     # Seuil de similaritÃ© minimum
USE_RERANKING=true          # Activer le re-ranking
```

## ğŸ“Š Ã‰valuation

Le systÃ¨me inclut des mÃ©triques d'Ã©valuation RAG :
- **Faithfulness** : Le LLM reste-t-il fidÃ¨le aux sources ?
- **Answer Relevancy** : La rÃ©ponse rÃ©pond-elle Ã  la question ?
- **Context Precision** : Les chunks rÃ©cupÃ©rÃ©s sont-ils pertinents ?
- **Context Recall** : Tous les chunks nÃ©cessaires sont-ils rÃ©cupÃ©rÃ©s ?

```python
# TODO: Module d'Ã©valuation Ã  implÃ©menter
from src.evaluation import RAGEvaluator

evaluator = RAGEvaluator(generator)
metrics = evaluator.evaluate(test_questions)
```

## ğŸ”§ DÃ©veloppement

### Installation des dÃ©pendances de dÃ©veloppement

```bash
uv sync --extra dev
```

### Tests

```bash
pytest tests/
```

### Formatage du code

```bash
black src/ scripts/
ruff check src/ scripts/
```

### Notebooks Jupyter

```bash
jupyter notebook notebooks/
```

## ğŸ“ Structure des mÃ©tadonnÃ©es

Chaque chunk est enrichi avec :
- `source_file` : Fichier source
- `file_name` : Nom du fichier
- `section` : Section du document
- `category` : CatÃ©gorie (techniques_autorisees, sanctions, scoring, etc.)
- `article_reference` : RÃ©fÃ©rence d'article (ex: "Article 5.3")
- `chunk_id` : Identifiant du chunk

CatÃ©gories dÃ©tectÃ©es automatiquement :
- `techniques_autorisees`
- `sanctions`
- `scoring`
- `equipement`
- `regles_generales`

## ğŸš§ Roadmap

- [ ] Interface web Streamlit
- [ ] API REST FastAPI
- [ ] Module d'Ã©valuation RAGAS
- [ ] Support multilingue
- [ ] Analyse de vidÃ©os de combats
- [ ] Export de rapports PDF
- [ ] Mode quiz interactif avec tracking de progression

## ğŸ¤ Contribution

Les contributions sont bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“„ Licence

[Ã€ dÃ©finir]

## ğŸ“§ Contact

[Ã€ dÃ©finir]

---

**Note** : Ce systÃ¨me est conÃ§u pour la formation et l'assistance aux arbitres. Les dÃ©cisions officielles doivent toujours Ãªtre prises en rÃ©fÃ©rence directe au rÃ¨glement officiel du Kudo.
