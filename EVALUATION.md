# üìä √âvaluation du Syst√®me RAG-Kudo

## Vue d'ensemble

Ce document pr√©sente l'√©valuation quantitative du syst√®me RAG-Kudo en utilisant le framework **RAGAS** (Retrieval-Augmented Generation Assessment).

L'√©valuation mesure 4 m√©triques cl√©s pour garantir la qualit√© et la fiabilit√© des r√©ponses dans un contexte r√©glementaire.

---

## üéØ M√©triques RAGAS

### 1. **Faithfulness** (Fid√©lit√© aux Sources)
- **D√©finition** : Mesure si la r√©ponse est fid√®le aux documents sources sans ajout d'informations externes
- **Importance** : Critique dans un contexte r√©glementaire o√π l'exactitude est primordiale
- **Calcul** : % d'affirmations dans la r√©ponse qui peuvent √™tre v√©rifi√©es dans le contexte

### 2. **Answer Relevancy** (Pertinence de la R√©ponse)
- **D√©finition** : Mesure si la r√©ponse r√©pond bien √† la question pos√©e
- **Importance** : Garantit que l'utilisateur obtient l'information recherch√©e
- **Calcul** : Similarit√© cosinus entre la question et une question g√©n√©r√©e depuis la r√©ponse

### 3. **Context Precision** (Pr√©cision du Contexte)
- **D√©finition** : Mesure si les documents r√©cup√©r√©s sont pertinents pour la question
- **Importance** : Valide la qualit√© du syst√®me de retrieval
- **Calcul** : % de documents r√©cup√©r√©s qui sont r√©ellement utiles

### 4. **Context Recall** (Rappel du Contexte)
- **D√©finition** : Mesure si tous les √©l√©ments n√©cessaires ont √©t√© r√©cup√©r√©s
- **Importance** : Garantit qu'aucune information importante n'est manqu√©e
- **Calcul** : % d'informations de la ground truth pr√©sentes dans le contexte r√©cup√©r√©

---

## üìà R√©sultats - Baseline (v1.0)

### Dataset de Test
- **Nombre de questions** : 10
- **Source** : R√®glement officiel d'arbitrage Kudo (30 pages, PDF fran√ßais)
- **Th√©matiques** : Scoring, √©quipement, techniques autoris√©es, dur√©es, p√©nalit√©s

### R√©sultats Quantitatifs

| M√©trique | Score | Interpr√©tation | Statut |
|----------|-------|----------------|--------|
| **Faithfulness** | **55.6%** | Environ 44% de la r√©ponse contient des informations non pr√©sentes dans les sources | ‚ö†Ô∏è **PROBL√àME** |
| **Answer Relevancy** | **86.3%** | Les r√©ponses sont pertinentes et r√©pondent bien aux questions | ‚úÖ BON |
| **Context Precision** | **71.8%** | Environ 72% des documents r√©cup√©r√©s sont pertinents | ‚úÖ BON |
| **Context Recall** | **80.0%** | 80% des informations n√©cessaires sont r√©cup√©r√©es | ‚úÖ BON |

### üîç Analyse des R√©sultats

#### ‚úÖ Points Forts
- **Retrieval efficace** : Context Precision (71.8%) et Context Recall (80.0%) montrent que le syst√®me r√©cup√®re bien les bons documents
- **Pertinence √©lev√©e** : Answer Relevancy (86.3%) indique que les r√©ponses sont align√©es avec les questions

#### ‚ö†Ô∏è Point Faible Identifi√©
- **Faithfulness faible (55.6%)** : Le LLM ajoute ~44% d'informations non pr√©sentes dans les sources
  - **Cause** : Prompts trop permissifs permettant au LLM d'utiliser ses connaissances g√©n√©rales
  - **Risque** : G√©n√©ration d'informations incorrectes ou non v√©rifi√©es dans un contexte r√©glementaire

---

## üîß Optimisations Appliqu√©es (v2.0)

### 1. **Renforcement des Prompts Syst√®me**

#### Avant
```python
SYSTEM_PROMPT = """Tu es un formateur expert en arbitrage de Kudo.
R√©ponds de mani√®re claire et p√©dagogique en te basant sur le contexte fourni.
Structure ta r√©ponse avec des exemples concrets."""
```

#### Apr√®s
```python
SYSTEM_PROMPT = """Tu es un formateur expert en arbitrage de Kudo.

R√àGLES STRICTES √Ä RESPECTER:
1. Tu dois UNIQUEMENT utiliser les informations pr√©sentes dans le contexte fourni
2. Si une information n'est PAS dans le contexte, tu DOIS dire "Je n'ai pas cette information dans le r√®glement fourni"
3. NE JAMAIS inventer, extrapoler ou ajouter des informations de ta connaissance g√©n√©rale
4. Cite EXACTEMENT les passages du r√®glement sans les reformuler de mani√®re substantielle
5. Si le contexte ne contient pas assez d'informations pour r√©pondre compl√®tement, indique-le clairement

Format de r√©ponse:
- Commence par citer la r√®gle exacte du contexte
- Explique ensuite de mani√®re p√©dagogique EN RESTANT FID√àLE au texte source
- Si tu donnes un exemple, assure-toi qu'il est directement bas√© sur le contexte fourni"""
```

### 2. **R√©duction de la Temp√©rature**
- **Avant** : `temperature = 0.1`
- **Apr√®s** : `temperature = 0.0`
- **Impact** : R√©ponses plus d√©terministes et moins cr√©atives (moins d'hallucinations)

### 3. **Am√©lioration du Prompt Utilisateur**
- S√©paration claire : `CONTEXTE` / `QUESTION` / `INSTRUCTIONS`
- Emphase sur "UNIQUEMENT les informations du contexte"
- Instruction explicite de signaler les informations manquantes

---

## üéØ R√©sultats Attendus (v2.0)

### Hypoth√®ses d'Am√©lioration

| M√©trique | Baseline (v1.0) | Objectif (v2.0) | Am√©lioration Attendue |
|----------|-----------------|-----------------|----------------------|
| **Faithfulness** | 55.6% | **> 75%** | **+20 points** |
| Answer Relevancy | 86.3% | ~85% | Stable |
| Context Precision | 71.8% | ~72% | Stable |
| Context Recall | 80.0% | ~80% | Stable |

**Note** : Une l√©g√®re baisse de Answer Relevancy est acceptable si elle r√©sulte d'une plus grande prudence (r√©ponses "je ne sais pas" quand l'info manque).

---

## üìù Exemples de Questions du Dataset

### Question 1 - Scoring
**Question** : "Quelle est la valeur en points d'un ippon en Kudo ?"

**Ground Truth** : "Un ippon vaut 8 points en Kudo. Il est attribu√© uniquement en cas de soumission ou de KO/TKO."

**√âvaluation** : Teste la capacit√© √† extraire une information factuelle pr√©cise.

---

### Question 2 - Techniques Autoris√©es
**Question** : "Quelles sont les techniques de frappe autoris√©es en Kudo ?"

**Ground Truth** : "Les techniques de frappe autoris√©es en Kudo incluent les coups de poing, les coups de pied, les coups de genou, les coups de coude et les coups de t√™te."

**√âvaluation** : Teste l'exhaustivit√© et la pr√©cision des listes.

---

### Question 3 - R√®gles Sp√©cifiques
**Question** : "Dans quel cas les frappes g√©nitales sont-elles autoris√©es ?"

**Ground Truth** : "Les frappes g√©nitales sont interdites et constituent une faute, sauf dans un cas particulier sp√©cifique : lorsqu'il y a un √©cart de 25 kg entre les deux adversaires et que cela est sp√©cifi√© d√®s le d√©but du combat."

**√âvaluation** : Teste la capacit√© √† g√©rer des cas exceptionnels et des nuances r√©glementaires.

---

## üîÑ M√©thodologie d'√âvaluation

### Pipeline d'√âvaluation

```
1. Chargement du dataset (10 questions + ground truths)
   ‚Üì
2. Pour chaque question:
   - Retrieval de documents pertinents
   - Extraction du contexte
   - G√©n√©ration de la r√©ponse
   ‚Üì
3. Cr√©ation du dataset RAGAS
   - question, answer, contexts, ground_truth
   ‚Üì
4. Calcul des m√©triques RAGAS
   - Faithfulness, Answer Relevancy, Context Precision, Context Recall
   ‚Üì
5. Analyse et sauvegarde des r√©sultats
```

### Configuration
- **LLM pour g√©n√©ration** : `gpt-4-turbo` (temp√©rature variable)
- **LLM pour √©valuation RAGAS** : `gpt-4-turbo` (temp√©rature 0.0)
- **Embeddings** : `text-embedding-3-small`
- **Re-ranker** : `cross-encoder/ms-marco-MiniLM-L-6-v2`
- **Top-k retrieval** : 5 documents

---

## üõ†Ô∏è Reproduction de l'√âvaluation

### Pr√©requis
```bash
# API Keys n√©cessaires
export OPENAI_API_KEY="sk-..."

# Installation
uv sync
```

### Ex√©cution
```bash
# √âvaluation compl√®te (10 questions)
uv run python scripts/run_evaluation.py

# Analyse des r√©sultats
uv run python scripts/analyze_results.py

# R√©sultats sauvegard√©s dans
data/evaluation/results.csv
```

### Co√ªts Estim√©s
- **Baseline** : ~$0.50 - $1.00 (10 questions √ó 4 m√©triques)
- **Note** : RAGAS appelle GPT-4 plusieurs fois par question pour calculer les m√©triques

---

## üìö R√©f√©rences

- [RAGAS Framework](https://docs.ragas.io/)
- [RAGAS Paper (arXiv)](https://arxiv.org/abs/2309.15217)
- [LlamaIndex RAGAS Integration](https://docs.llamaindex.ai/en/stable/examples/evaluation/ragas_evaluation/)

---

## üîÆ Prochaines √âtapes

1. **R√©√©valuation post-optimisation** (n√©cessite recharge quota OpenAI)
2. **√âvaluation humaine** pour validation qualitative
3. **A/B testing** avec arbitres r√©els
4. **Expansion du dataset** √† 50-100 questions
5. **Fine-tuning** potentiel si Faithfulness reste < 80%
